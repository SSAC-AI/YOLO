# YOLO (You Only Look Once)

## 개요
YOLO(You Only Look Once)는 객체 탐지(Object Detection) 분야에서 널리 사용되는 딥러닝 기반 알고리즘으로, 이미지나 영상에서 여러 객체를 실시간으로 탐지하고 분류하는 데 최적화되어 있습니다. 기존의 R-CNN 계열 탐지기들이 후보 영역(Region Proposal)을 여러 단계에 걸쳐 처리하는 데 비해, YOLO는 단일 신경망을 통해 이미지를 한 번만 보고 객체의 위치와 클래스 확률을 동시에 예측합니다.

---

## YOLO의 필요성 및 배경
기존 객체 탐지 방식은 주로 두 단계(2-stage)로 구성됩니다:
- **1단계:** 후보 영역(Region Proposal) 생성 (예: Selective Search)
- **2단계:** 후보 영역별 분류 및 경계 박스 조정

이 과정은 정확하지만 속도가 느리고 복잡합니다. 반면 YOLO는 이를 하나의 통합된 신경망으로 해결하여 실시간 성능을 대폭 향상시켰습니다.

---

## 주요 특징

| 특징             | 설명                                                         |
|----------------|------------------------------------------------------------|
| **단일 네트워크**   | 이미지를 SxS 그리드로 나누고 각 셀이 바운딩 박스와 클래스 확률을 예측              |
| **빠른 속도**       | 이미지를 한 번만 처리하여 초당 수십 프레임 이상 처리 가능                        |
| **높은 정확도**      | 배경과 객체를 구분하는 능력이 뛰어나며, 특히 작은 객체 탐지에서 발전 중           |
| **End-to-End 학습** | 전체 모델을 한꺼번에 학습시켜 오류 전파가 효과적으로 이루어짐                   |
| **실시간 적용 가능** | 자율주행, CCTV 감시, 드론, 로봇 등 실시간 객체 탐지가 필요한 분야에 적합           |

---

## YOLO 아키텍처 상세

### 1. 입력 처리
- 입력 이미지를 고정된 크기 (예: 448x448, 416x416)로 리사이징 후 네트워크에 입력
- 이미지 전체를 한 번에 처리하기 때문에 공간적 정보를 잘 활용

### 2. 그리드 분할
- 이미지 공간을 SxS 크기의 그리드로 나눔 (예: 7x7)
- 각 그리드 셀은 해당 영역에 중심이 위치한 객체에 대해 예측을 담당

### 3. 바운딩 박스 예측
- 각 셀에서 B개의 바운딩 박스를 예측 (예: 2개)
- 각 박스는 위치(x, y), 크기(w, h), 신뢰도(confidence)를 포함
- 신뢰도는 “객체가 박스 내에 존재할 확률 × 박스가 정확한 위치임을 나타내는 IoU”로 정의

### 4. 클래스 확률 예측
- 각 셀마다 C개의 클래스에 대한 확률을 예측
- 클래스 확률과 바운딩 박스 신뢰도를 곱해 최종 객체별 확률 계산

### 5. 비최대 억제 (Non-Maximum Suppression, NMS)
- 중복된 박스 제거를 위해 NMS 적용
- 동일 객체를 여러 박스가 탐지한 경우 신뢰도 높은 박스만 남김

---

## YOLO 버전별 발전

| 버전    | 주요 개선사항                                             |
|-------|---------------------------------------------------------|
| YOLOv1 | 최초 제안, 빠른 속도, 낮은 정확도 특히 작은 객체 탐지에 한계       |
| YOLOv2 (YOLO9000) | 앵커 박스 도입, 더 깊은 네트워크, 다양한 클래스 동시 학습 지원       |
| YOLOv3 | 다중 스케일 탐지, 잔여 연결(Residual connection) 도입, 정확도 대폭 향상  |
| YOLOv4 | CSPDarknet53 백본, 개선된 데이터 증강과 정규화 기법 적용           |
| YOLOv5 | PyTorch 기반 경량화 및 최적화, 쉬운 사용과 빠른 학습                   |
| YOLOv7 | 최신 성능 최적화, 속도와 정확도 모두 향상                          |
| YOLOv8 | PyTorch 기반, 더욱 향상된 정확도 및 속도, 다양한 크기 및 플랫폼 지원, 개선된 앵커 박스 및 네트워크 구조 |
| YOLOv11 | 다중 작업 지원(탐지, 분할, 자세 추정 등), 효율성 및 속도 향상, 25개 모델 제공, COCO mAP 39.5% 달성 |
| YOLOv12 | 영역 기반 주의 메커니즘(A²) 도입, R-ELAN 특징 집합 모듈, FlashAttention 최적화, 실시간 성능 및 정확도 대폭 향상 |
---

